{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3gb4KL+/vxdTVnvUEvxP9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thepersonuadmire/MLLinear/blob/main/ML_L2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Theoretical**"
      ],
      "metadata": {
        "id": "pOqdu7yHfZ-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What does R-squared represent in a regression model?"
      ],
      "metadata": {
        "id": "Cs2mKp0IftPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " R-squared, or the coefficient of determination, represents the proportion of the variance in the dependent variable that can be explained by the independent variables in the model. It ranges from 0 to 1, where a higher value indicates a better fit of the model to the data."
      ],
      "metadata": {
        "id": "AxrCDTzIkID4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the assumptions of linear regression?"
      ],
      "metadata": {
        "id": "v0pAWQB1gMnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main assumptions of linear regression include:\n",
        "\n",
        "Linearity: The relationship between the independent and dependent variables is linear.\n",
        "\n",
        "Independence: The residuals (errors) are independent.\n",
        "\n",
        "Homoscedasticity: The residuals have constant variance at all levels of the independent variables.\n",
        "\n",
        "Normality: The residuals are normally distributed.\n",
        "\n",
        "No multicollinearity: The independent variables are not highly correlated with each other."
      ],
      "metadata": {
        "id": "p09TYrqAkOQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the difference between R-squared and Adjusted R-squared?"
      ],
      "metadata": {
        "id": "gQMbWohMgRB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-squared measures the proportion of variance explained by the model, while Adjusted R-squared adjusts R-squared for the number of predictors in the model. Adjusted R-squared can decrease if adding more predictors does not improve the model, making it a better metric for comparing models with different numbers of predictors."
      ],
      "metadata": {
        "id": "BZFopIw2kXY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Why do we use Mean Squared Error (MSE)?"
      ],
      "metadata": {
        "id": "6gDoO9QMgVqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE is used to measure the average squared difference between the predicted and actual values. It provides a way to quantify the model's prediction error, with larger errors being penalized more due to the squaring of differences."
      ],
      "metadata": {
        "id": "-yqwyEiVkdk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What does an Adjusted R-squared value of 0.85 indicate?"
      ],
      "metadata": {
        "id": "zZLycCz3gZzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An Adjusted R-squared value of 0.85 indicates that 85% of the variance in the dependent variable can be explained by the independent variables in the model, after adjusting for the number of predictors. This suggests a strong model fit."
      ],
      "metadata": {
        "id": "4nRKaaCpkgtq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do we check for normality of residuals in linear regression?"
      ],
      "metadata": {
        "id": "Duog871Agdo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normality of residuals can be checked using:\n",
        "\n",
        "Q-Q plots (quantile-quantile plots)\n",
        "\n",
        "Histogram of residuals\n",
        "\n",
        "Statistical tests such as the Shapiro-Wilk test or the Kolmogorov-Smirnov test."
      ],
      "metadata": {
        "id": "CahcvLopkjvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is multicollinearity, and how does it impact regression?"
      ],
      "metadata": {
        "id": "dvKY468JghKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Multicollinearity occurs when two or more independent variables in a regression model are highly correlated. It can lead to unreliable coefficient estimates, inflated standard errors, and difficulties in determining the effect of each predictor."
      ],
      "metadata": {
        "id": "1b0YIcQBkq22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is Mean Absolute Error (MAE)?"
      ],
      "metadata": {
        "id": "8GdGhv-rgmhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAE is a measure of prediction accuracy that calculates the average absolute difference between predicted and actual values. It is less sensitive to outliers compared to MSE."
      ],
      "metadata": {
        "id": "PzgaVfRuk1ie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What are the benefits of using an ML pipeline?"
      ],
      "metadata": {
        "id": "BmVbwyF3groc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benefits of using an ML pipeline include:\n",
        "\n",
        "Streamlining the workflow from data preprocessing to model deployment.\n",
        "\n",
        "Ensuring reproducibility and consistency in model training and evaluation.\n",
        "\n",
        "Facilitating collaboration among team members.\n",
        "\n",
        "Simplifying the process of model updates and maintenance."
      ],
      "metadata": {
        "id": "6ATk6r_Dk48I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Why is RMSE considered more interpretable than MSE?"
      ],
      "metadata": {
        "id": "NvBGAQFKgxNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE (Root Mean Squared Error) is considered more interpretable than MSE because it is in the same units as the dependent variable, making it easier to understand the magnitude of the prediction errors."
      ],
      "metadata": {
        "id": "RF4y8hk3k_Wt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is pickling in Python, and how is it useful in ML?"
      ],
      "metadata": {
        "id": "YwtNicWxg1FZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pickling is the process of serializing Python objects into a byte stream, allowing them to be saved to a file and later deserialized back into the original object. In machine learning, it is useful for saving trained models for later use without needing to retrain them."
      ],
      "metadata": {
        "id": "T6IGf2sklDQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What does a high R-squared value mean?"
      ],
      "metadata": {
        "id": "8WopZMzrhBiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A high R-squared value indicates that a large proportion of the variance in the dependent variable is explained by the independent variables in the model, suggesting a good fit. However, it does not imply causation or that the model is the best one."
      ],
      "metadata": {
        "id": "Jd5vF111lIqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What happens if linear regression assumptions are violated?"
      ],
      "metadata": {
        "id": "CWpdW4IghGPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If linear regression assumptions are violated, it can lead to biased or inefficient estimates of the coefficients, incorrect conclusions about the significance of predictors, and unreliable predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "xkdmHjtqlMp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can we address multicollinearity in regression?"
      ],
      "metadata": {
        "id": "R_OM1UkMhKnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicollinearity can be addressed by:\n",
        "\n",
        "Removing highly correlated predictors.\n",
        "\n",
        "Combining correlated variables into a single predictor (e.g., using PCA).\n",
        "\n",
        "Using regularization techniques like Ridge or Lasso regression."
      ],
      "metadata": {
        "id": "zUoG3M5alm_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How can feature selection improve model performance in regression analysis?"
      ],
      "metadata": {
        "id": "Bv8QwvqkhPE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection can improve model performance by reducing overfitting, enhancing model interpretability, and decreasing computational cost. It helps in identifying the most relevant predictors that contribute to the model's predictive power."
      ],
      "metadata": {
        "id": "DYoO19QRltYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How is Adjusted R-squared calculated?"
      ],
      "metadata": {
        "id": "HfvfuTojhS4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjusted R-squared is calculated using the formula:\n",
        "\n",
        "[ \\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - p - 1} \\right) ]\n",
        "\n",
        "where ( R^2 ) is the R-squared value, ( n ) is the number of observations, and ( p ) is the number of predictors in the model. This adjustment accounts for the number of predictors, providing a more accurate measure of model fit when comparing models with different numbers of predictors."
      ],
      "metadata": {
        "id": "oTmoKFaAlxhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Why is MSE sensitive to outliers?"
      ],
      "metadata": {
        "id": "7eYUA8JBhaYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " MSE is sensitive to outliers because it squares the differences between predicted and actual values. This squaring means that larger errors have a disproportionately large effect on the overall error metric, which can skew the results and lead to misleading interpretations of model performance."
      ],
      "metadata": {
        "id": "nDDg5JxVmCXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the role of homoscedasticity in linear regression?"
      ],
      "metadata": {
        "id": "OBSJdy0bherr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homoscedasticity refers to the condition where the variance of the residuals is constant across all levels of the independent variables. It is important because violations of this assumption (heteroscedasticity) can lead to inefficient estimates and affect the validity of hypothesis tests."
      ],
      "metadata": {
        "id": "7mmzdLYSmGiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What is Root Mean Squared Error (RMSE)?"
      ],
      "metadata": {
        "id": "J2b_W_XJhkO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " RMSE is the square root of the average of the squared differences between predicted and actual values. It provides a measure of how well a model predicts the outcome variable, with lower values indicating better model performance."
      ],
      "metadata": {
        "id": "6X8M_PFKmJm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Why is pickling considered risky?"
      ],
      "metadata": {
        "id": "a5fFYu1IhoOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pickling can be considered risky because it can lead to security vulnerabilities if untrusted data is deserialized. Additionally, changes in the code or libraries used to create the pickled objects can result in compatibility issues when trying to unpickle the data later."
      ],
      "metadata": {
        "id": "U8HJhKwQmNme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What alternatives exist to pickling for saving ML models?"
      ],
      "metadata": {
        "id": "Ayw9uS1ohscf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatives to pickling for saving machine learning models include:\n",
        "\n",
        "Using joblib, which is optimized for large numpy arrays.\n",
        "\n",
        "Saving models in formats like ONNX or PMML for interoperability.\n",
        "\n",
        "Utilizing frameworks like TensorFlow or PyTorch that provide their own model saving mechanisms."
      ],
      "metadata": {
        "id": "8BjM-kxzmRHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What is heteroscedasticity, and why is it a problem?"
      ],
      "metadata": {
        "id": "P8wW-5Wzhx_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heteroscedasticity occurs when the variance of the residuals is not constant across all levels of the independent variables. It is a problem because it can lead to inefficient estimates and affect the validity of statistical tests, potentially resulting in misleading conclusions."
      ],
      "metadata": {
        "id": "xhwYHieVmYYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. How can interaction terms enhance a regression model's predictive power?"
      ],
      "metadata": {
        "id": "uGoanqj9h2Yx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interaction terms can enhance a regression model's predictive power by allowing the model to capture the combined effect of two or more independent variables on the dependent variable. This can reveal more complex relationships that a simple additive model might miss, leading to improved predictions."
      ],
      "metadata": {
        "id": "rO-0arKZmZUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical**"
      ],
      "metadata": {
        "id": "Kydmacm2h8F4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python script to visualize the distribution of errors (residuals) for a multiple linear regression model using Seaborn's \"diamonds\" dataset."
      ],
      "metadata": {
        "id": "k2AgHa-FiEB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load diamonds dataset\n",
        "data = sns.load_dataset('diamonds')\n",
        "data = data.dropna()\n",
        "\n",
        "# Prepare features and target\n",
        "X = data[['carat', 'depth', 'table', 'x', 'y', 'z']]\n",
        "y = data['price']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate residuals\n",
        "y_pred = model.predict(X_test)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Plot residual distribution\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QBLOIjeCmiF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a Python script to calculate and print Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) for a linear regression model."
      ],
      "metadata": {
        "id": "TFw6J3IWiRmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Calculate errors\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Print results\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "id": "ARd4rO11mjlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a Python script to check if the assumptions of linear regression are met. Use a scatter plot to check linearity, residuals plot for homoscedasticity, and correlation matrix for multicollinearity.\n"
      ],
      "metadata": {
        "id": "Eqp5Nz8fiV2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scatter plot for linearity\n",
        "sns.scatterplot(x=y_test, y=y_pred)\n",
        "plt.title('Linearity Check')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.show()\n",
        "\n",
        "# Residuals plot for homoscedasticity\n",
        "sns.residplot(x=y_pred, y=residuals, lowess=True, line_kws={'color': 'red'})\n",
        "plt.title('Homoscedasticity Check')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Correlation matrix for multicollinearity\n",
        "corr_matrix = pd.DataFrame(X_train).corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix (Multicollinearity)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xq8xjchZmo2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python script that creates a machine learning pipeline with feature scaling and evaluates the performance of different regression models.\n"
      ],
      "metadata": {
        "id": "_J05JrinjTyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', RandomForestRegressor())\n",
        "])\n",
        "\n",
        "# Evaluate model\n",
        "scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
        "print(f\"Average R-squared Score: {scores.mean()}\")\n"
      ],
      "metadata": {
        "id": "HH7WekuwmvpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Implement a simple linear regression model on a dataset and print the model's coefficients, intercept, and R-squared score.\n"
      ],
      "metadata": {
        "id": "vdlzNM-NjV-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Coefficients: {model.coef_}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"R-squared Score: {model.score(X_test, y_test)}\")\n"
      ],
      "metadata": {
        "id": "hmtJIYClmyxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python script that analyzes the relationship between total bill and tip in the 'tips' dataset using simple linear regression and visualizes the results.\n"
      ],
      "metadata": {
        "id": "Bet79_XDjYj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tips = sns.load_dataset('tips')\n",
        "X = tips[['total_bill']]\n",
        "y = tips['tip']\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "sns.regplot(x='total_bill', y='tip', data=tips, line_kws={'color': 'red'})\n",
        "plt.title('Total Bill vs Tip')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cPyeerqHm1xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python script that fits a linear regression model to a synthetic dataset with one feature. Use the model to predict new values and plot the data points along with the regression line.\n"
      ],
      "metadata": {
        "id": "DZPJ842gjbRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 2.5 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Plot regression line\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X), color='red')\n",
        "plt.title('Linear Regression on Synthetic Data')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A26-UvuQneps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Write a Python script that pickles a trained linear regression model and saves it to a file.\n"
      ],
      "metadata": {
        "id": "v9GOIW8qjdi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('linear_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "print(\"Model saved to linear_model.pkl\")\n"
      ],
      "metadata": {
        "id": "KgpIU9UDni_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python script that fits a polynomial regression model (degree 2) to a dataset and plots the regression curve.\n"
      ],
      "metadata": {
        "id": "aRw1HKlTjfwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X_poly), color='red')\n",
        "plt.title('Polynomial Regression Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "63WFlojrnmei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Generate synthetic data for simple linear regression (use random values for X and y) and fit a linear regression model to the data. Print the model's coefficient and intercept.\n"
      ],
      "metadata": {
        "id": "SYOEKuVqjirg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Coefficient: {model.coef_[0]}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n"
      ],
      "metadata": {
        "id": "Bhln8p_hnpzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Write a Python script that fits polynomial regression models of different degrees to a synthetic dataset and compares their performance.\n"
      ],
      "metadata": {
        "id": "n9z0XJ9vjkwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "degrees = [1, 2, 3, 4]\n",
        "for degree in degrees:\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    model.fit(X_poly, y)\n",
        "    print(f\"Degree {degree} R-squared: {model.score(X_poly, y)}\")\n"
      ],
      "metadata": {
        "id": "_8QSawbuntUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Write a Python script that fits a simple linear regression model with two features and prints the model's coefficients, intercept, and R-squared score.\n"
      ],
      "metadata": {
        "id": "cKVlDGYTjnOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['carat', 'depth']]\n",
        "model.fit(X, y)\n",
        "\n",
        "print(f\"Coefficients: {model.coef_}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"R-squared Score: {model.score(X_test[['carat', 'depth']], y_test)}\")\n"
      ],
      "metadata": {
        "id": "Sj17VIJznw50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python script that generates synthetic data, fits a linear regression model, and visualizes the regression line along with the data points.\n"
      ],
      "metadata": {
        "id": "d9vjaDCTjpz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X), color='red')\n",
        "plt.title('Regression Line')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tQN-_jEEn0sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python script that uses the Variance Inflation Factor (VIF) to check for multicollinearity in a dataset with multiple features.\n"
      ],
      "metadata": {
        "id": "Ou83xO_6jrxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "X = pd.DataFrame({\n",
        "    'Feature_1': np.random.rand(100),\n",
        "    'Feature_2': np.random.rand(100) * 0.5,\n",
        "    'Feature_3': np.random.rand(100) * 1.5,\n",
        "    'Feature_4': np.random.rand(100) * 2\n",
        "})\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Compute VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
        "\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "id": "M_pwMgk5n3tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Write a Python script that generates synthetic data for a polynomial relationship (degree 4), fits a polynomial regression model, and plots the regression curve.\n"
      ],
      "metadata": {
        "id": "VVIAMVKgjufQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate synthetic data\n",
        "X = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
        "y = X**4 - 3*X**3 + 2*X**2 + np.random.randn(100, 1) * 10\n",
        "\n",
        "# Fit polynomial regression\n",
        "poly = PolynomialFeatures(degree=4)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Plot results\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X_poly), color='red')\n",
        "plt.title(\"Polynomial Regression (Degree 4)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OBGVznnXn78J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Write a Python script that creates a machine learning pipeline with data standardization and a multiple linear regression model, and prints the R-squared score.\n"
      ],
      "metadata": {
        "id": "yNCBg1T9jxVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate synthetic dataset\n",
        "X = np.random.rand(100, 3)\n",
        "y = 2*X[:,0] + 3*X[:,1] - 1.5*X[:,2] + np.random.randn(100)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit model and evaluate\n",
        "pipeline.fit(X_train, y_train)\n",
        "r_squared = pipeline.score(X_test, y_test)\n",
        "print(f\"R-squared Score: {r_squared}\")\n"
      ],
      "metadata": {
        "id": "YzVMwBzAn-u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python script that performs polynomial regression (degree 3) on a synthetic dataset and plots the regression curve.\n"
      ],
      "metadata": {
        "id": "9kXTJnWLjzSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=3)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X_poly), color='red')\n",
        "plt.title(\"Polynomial Regression (Degree 3)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hOqYrz_XoCFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python script that performs multiple linear regression on a synthetic dataset with 5 features. Print the R-squared score and model coefficients.\n"
      ],
      "metadata": {
        "id": "2nwqwMzcj1GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.rand(100, 5)\n",
        "y = 2*X[:,0] - 1.5*X[:,1] + 3*X[:,2] + np.random.randn(100)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(f\"R-squared Score: {model.score(X, y)}\")\n",
        "print(f\"Coefficients: {model.coef_}\")\n"
      ],
      "metadata": {
        "id": "LYHyDaOnoGII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python script that generates synthetic data for linear regression, fits a model, and visualizes the data points along with the regression line.\n"
      ],
      "metadata": {
        "id": "5BIWeZeHj3qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:,0], y, color='blue')\n",
        "plt.plot(X[:,0], model.predict(X), color='red')\n",
        "plt.title(\"Linear Regression Line\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iWjTX_ieoNCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Create a synthetic dataset with 3 features and perform multiple linear regression. Print the model's R-squared score and coefficients.\n"
      ],
      "metadata": {
        "id": "68mlHwFWj6s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.rand(100, 3)\n",
        "y = 2*X[:,0] + 1.2*X[:,1] - 0.8*X[:,2] + np.random.randn(100)\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "print(f\"R-squared Score: {model.score(X, y)}\")\n",
        "print(f\"Coefficients: {model.coef_}\")\n"
      ],
      "metadata": {
        "id": "q85fdmtNoPlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python script that demonstrates how to serialize and deserialize machine learning models using joblib instead of pickling.\n"
      ],
      "metadata": {
        "id": "v8JzkaR4j8XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'model.joblib')\n",
        "loaded_model = joblib.load('model.joblib')\n",
        "\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "id": "cXrEPuFvoSXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python script to perform linear regression with categorical features using one-hot encoding. Use the Seaborn 'tips' dataset.\n"
      ],
      "metadata": {
        "id": "QNdGP-E3j-NR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "X = tips[['total_bill', 'sex', 'smoker', 'day']]\n",
        "y = tips['tip']\n",
        "\n",
        "# One-hot encoding categorical variables\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(drop='first'), ['sex', 'smoker', 'day'])\n",
        "], remainder='passthrough')\n",
        "\n",
        "X_transformed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_transformed, y)\n",
        "print(f\"R-squared Score: {model.score(X_transformed, y)}\")\n"
      ],
      "metadata": {
        "id": "dMhHxWYaoVMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Compare Ridge Regression with Linear Regression on a synthetic dataset and print the coefficients and R-squared score.\n"
      ],
      "metadata": {
        "id": "4zgHcOlOkAF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X, y)\n",
        "\n",
        "print(f\"Linear Regression Coefficients: {model.coef_}\")\n",
        "print(f\"Ridge Regression Coefficients: {ridge.coef_}\")\n",
        "print(f\"Linear Regression R-squared: {model.score(X, y)}\")\n",
        "print(f\"Ridge Regression R-squared: {ridge.score(X, y)}\")\n"
      ],
      "metadata": {
        "id": "8mOF_faaoYUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python script that uses cross-validation to evaluate a Linear Regression model on a synthetic dataset.\n"
      ],
      "metadata": {
        "id": "1689vmVkkC2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "print(f\"Cross-validated R-squared scores: {cv_scores}\")\n",
        "print(f\"Mean R-squared: {np.mean(cv_scores)}\")\n"
      ],
      "metadata": {
        "id": "NQSwY6b9oa7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python script that compares polynomial regression models of different degrees and prints the R-squared score for each."
      ],
      "metadata": {
        "id": "uZTdqZjKkEti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for degree in range(1, 5):\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    model.fit(X_poly, y)\n",
        "    print(f\"Degree {degree} R-squared: {model.score(X_poly, y)}\")\n"
      ],
      "metadata": {
        "id": "mhNUK8SpodeK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}